{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c526b5",
   "metadata": {
    "id": "b1c526b5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import dill\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, recall_score, precision_score, fbeta_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2GSaOUdStQrg",
   "metadata": {
    "id": "2GSaOUdStQrg"
   },
   "outputs": [],
   "source": [
    "rnd = 42\n",
    "train = pd.read_csv('df_train_ADASYN_MinMax.csv')\n",
    "test =  pd.read_csv('df_test_ADASYN_MinMax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051b705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target', axis = 1)\n",
    "y = train['target']\n",
    "X_test = test.drop('target', axis = 1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52f0c82",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1404b705",
   "metadata": {
    "id": "1404b705",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "[CV 3/3] END .....max_depth=7, n_estimators=150;, score=0.883 total time= 4.3min\n",
      "[CV 3/3] END .....max_depth=20, n_estimators=80;, score=0.962 total time= 5.8min\n",
      "[CV 2/3] END .....max_depth=30, n_estimators=80;, score=0.966 total time= 6.4min\n",
      "[CV 3/3] END ......max_depth=7, n_estimators=80;, score=0.883 total time= 2.1min\n",
      "[CV 1/3] END ....max_depth=12, n_estimators=300;, score=0.885 total time=15.0min\n",
      "[CV 1/3] END .....max_depth=12, n_estimators=50;, score=0.882 total time= 2.1min\n",
      "[CV 3/3] END ....max_depth=12, n_estimators=300;, score=0.932 total time=15.1min\n",
      "[CV 3/3] END .....max_depth=12, n_estimators=50;, score=0.930 total time= 2.1min\n",
      "[CV 2/3] END ....max_depth=12, n_estimators=300;, score=0.925 total time=15.3min\n",
      "[CV 2/3] END ......max_depth=7, n_estimators=50;, score=0.872 total time= 1.4min\n",
      "[CV 1/3] END ....max_depth=12, n_estimators=200;, score=0.884 total time= 9.9min\n",
      "[CV 3/3] END .....max_depth=30, n_estimators=80;, score=0.969 total time= 6.4min\n",
      "[CV 1/3] END ....max_depth=12, n_estimators=150;, score=0.884 total time= 7.1min\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=300;, score=0.963 total time=16.4min\n",
      "[CV 1/3] END .....max_depth=7, n_estimators=150;, score=0.847 total time= 4.5min\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=100;, score=0.907 total time= 6.9min\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=100;, score=0.909 total time= 7.3min\n",
      "[CV 1/3] END .....max_depth=7, n_estimators=200;, score=0.847 total time= 6.1min\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=200;, score=0.906 total time=12.9min\n",
      "[CV 2/3] END ....max_depth=12, n_estimators=100;, score=0.923 total time= 4.6min\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=100;, score=0.962 total time= 7.1min\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=100;, score=0.970 total time= 7.3min\n",
      "[CV 3/3] END .....max_depth=7, n_estimators=200;, score=0.883 total time= 6.1min\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=200;, score=0.959 total time=13.0min\n",
      "[CV 3/3] END ....max_depth=12, n_estimators=100;, score=0.931 total time= 4.6min\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=100;, score=0.959 total time= 7.0min\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=100;, score=0.966 total time= 7.5min\n",
      "[CV 1/3] END .....max_depth=7, n_estimators=100;, score=0.847 total time= 2.9min\n",
      "[CV 1/3] END .....max_depth=20, n_estimators=50;, score=0.905 total time= 3.5min\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=200;, score=0.962 total time=12.9min\n",
      "[CV 2/3] END .....max_depth=12, n_estimators=50;, score=0.921 total time= 2.2min\n",
      "[CV 1/3] END ....max_depth=12, n_estimators=400;, score=0.885 total time=18.3min\n",
      "[CV 2/3] END .....max_depth=7, n_estimators=100;, score=0.873 total time= 2.8min\n",
      "[CV 3/3] END ....max_depth=12, n_estimators=400;, score=0.931 total time=17.9min\n",
      "[CV 1/3] END ......max_depth=7, n_estimators=80;, score=0.847 total time= 2.4min\n",
      "[CV 2/3] END ....max_depth=12, n_estimators=400;, score=0.925 total time=18.3min\n",
      "[CV 2/3] END ......max_depth=7, n_estimators=80;, score=0.874 total time= 2.1min\n",
      "[CV 3/3] END ....max_depth=12, n_estimators=200;, score=0.932 total time=10.2min\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=150;, score=0.967 total time= 9.3min\n",
      "[CV 1/3] END ......max_depth=7, n_estimators=50;, score=0.847 total time= 1.5min\n",
      "[CV 2/3] END ....max_depth=12, n_estimators=200;, score=0.924 total time=10.6min\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=150;, score=0.909 total time= 9.4min\n",
      "[CV 3/3] END .....max_depth=7, n_estimators=400;, score=0.884 total time=12.6min\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=150;, score=0.970 total time= 9.1min\n",
      "[CV 3/3] END .....max_depth=7, n_estimators=100;, score=0.882 total time= 3.2min\n",
      "[CV 2/3] END .....max_depth=20, n_estimators=50;, score=0.955 total time= 3.6min\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=300;, score=0.906 total time=16.4min\n",
      "[CV 2/3] END ....max_depth=12, n_estimators=150;, score=0.924 total time= 7.1min\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=300;, score=0.960 total time=16.4min\n",
      "[CV 2/3] END .....max_depth=7, n_estimators=400;, score=0.875 total time=12.7min\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=200;, score=0.909 total time=10.9min\n",
      "[CV 1/3] END .....max_depth=7, n_estimators=400;, score=0.848 total time=12.8min\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=200;, score=0.967 total time=11.1min\n",
      "[CV 3/3] END .....max_depth=7, n_estimators=300;, score=0.884 total time= 9.3min\n",
      "[CV 1/3] END .....max_depth=30, n_estimators=50;, score=0.906 total time= 4.1min\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=200;, score=0.970 total time=10.8min\n",
      "[CV 1/3] END .....max_depth=12, n_estimators=80;, score=0.883 total time= 3.4min\n",
      "[CV 3/3] END .....max_depth=20, n_estimators=50;, score=0.961 total time= 3.7min\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=400;, score=0.907 total time=19.5min\n",
      "[CV 3/3] END ......max_depth=7, n_estimators=50;, score=0.882 total time= 1.3min\n",
      "[CV 3/3] END ....max_depth=12, n_estimators=150;, score=0.932 total time= 7.2min\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=400;, score=0.960 total time=18.9min\n",
      "[CV 1/3] END .....max_depth=7, n_estimators=300;, score=0.848 total time= 9.1min\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=400;, score=0.963 total time=18.8min\n",
      "[CV 2/3] END .....max_depth=7, n_estimators=300;, score=0.874 total time= 9.3min\n",
      "[CV 3/3] END .....max_depth=30, n_estimators=50;, score=0.968 total time= 4.1min\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=300;, score=0.909 total time=14.6min\n",
      "[CV 3/3] END .....max_depth=12, n_estimators=80;, score=0.931 total time= 3.7min\n",
      "[CV 1/3] END .....max_depth=20, n_estimators=80;, score=0.906 total time= 5.6min\n",
      "[CV 2/3] END .....max_depth=30, n_estimators=50;, score=0.965 total time= 4.3min\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=300;, score=0.968 total time=14.8min\n",
      "[CV 2/3] END .....max_depth=7, n_estimators=150;, score=0.874 total time= 4.8min\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=150;, score=0.906 total time=10.5min\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=300;, score=0.971 total time=13.7min\n",
      "[CV 2/3] END .....max_depth=7, n_estimators=200;, score=0.874 total time= 5.7min\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=150;, score=0.962 total time=10.3min\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=400;, score=0.968 total time=18.0min\n",
      "[CV 2/3] END .....max_depth=12, n_estimators=80;, score=0.923 total time= 4.2min\n",
      "[CV 2/3] END .....max_depth=20, n_estimators=80;, score=0.958 total time= 5.6min\n",
      "[CV 1/3] END .....max_depth=30, n_estimators=80;, score=0.908 total time= 6.4min\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=400;, score=0.971 total time=18.0min\n",
      "[CV 1/3] END ....max_depth=12, n_estimators=100;, score=0.884 total time= 4.8min\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=150;, score=0.959 total time=10.8min\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=400;, score=0.909 total time=18.6min\n",
      "Best parameters: {'max_depth': 30, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [50, 80, 100, 150, 200,300,  400],\n",
    "    'max_depth': [7, 12, 20,30],\n",
    "}\n",
    "\n",
    "\n",
    "rf_model =RandomForestClassifier(random_state=rnd)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid=params, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b23dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(train, test):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    model = RandomForestClassifier(random_state = rnd, n_estimators=400, max_depth=30, n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    X_t = test.drop(['client_id', 'dt','target'],axis=1)\n",
    "    y_t = test['target'].to_numpy()\n",
    "\n",
    "    pred_proba = model.predict_proba(X_t)[:,1]\n",
    "    print('gini: ', round(2*roc_auc_score(y_t, pred_proba)-1,3))\n",
    "    pred = model.predict(X_t)\n",
    "    print('f1_score: ', round(f1_score(y_t, pred),3))\n",
    "    print('f2_score: ',  round(fbeta_score(y_t, pred,beta =2), 3))\n",
    "    print('accuracy_score: ', round(accuracy_score(y_t, pred),3))\n",
    "    print('recall_score: ', round(recall_score(y_t, pred),3))\n",
    "    print('precision_score: ', round(precision_score(y_t, pred),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe67157a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini:  0.356\n",
      "f1_score:  0.149\n",
      "f2_score:  0.299\n",
      "accuracy_score:  0.325\n",
      "recall_score:  0.913\n",
      "precision_score:  0.081\n"
     ]
    }
   ],
   "source": [
    "RF(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5HmRJKgyEBYw",
   "metadata": {
    "id": "5HmRJKgyEBYw"
   },
   "source": [
    "Альтернативный способ подбора гиперпараметров с помощью optune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "DPViQavrAhvg",
   "metadata": {
    "id": "DPViQavrAhvg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-01 16:01:37,943]\u001b[0m A new study created in memory with name: no-name-59da9bef-ff92-496c-a967-9c4ac9b3864d\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:02:31,238]\u001b[0m Trial 0 finished with value: 0.9661249758173728 and parameters: {'max_depth': 48, 'n_estimators': 387}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:03:01,139]\u001b[0m Trial 1 finished with value: 0.9552137744244534 and parameters: {'max_depth': 19, 'n_estimators': 260}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:03:56,952]\u001b[0m Trial 2 finished with value: 0.9661249758173728 and parameters: {'max_depth': 48, 'n_estimators': 416}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:04:08,317]\u001b[0m Trial 3 finished with value: 0.9218224027858386 and parameters: {'max_depth': 12, 'n_estimators': 105}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:05:07,862]\u001b[0m Trial 4 finished with value: 0.9656800154768814 and parameters: {'max_depth': 37, 'n_estimators': 459}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:05:57,415]\u001b[0m Trial 5 finished with value: 0.9656993615786419 and parameters: {'max_depth': 47, 'n_estimators': 386}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:06:45,878]\u001b[0m Trial 6 finished with value: 0.8966337782936739 and parameters: {'max_depth': 9, 'n_estimators': 779}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:07:08,047]\u001b[0m Trial 7 finished with value: 0.9656993615786419 and parameters: {'max_depth': 44, 'n_estimators': 149}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:08:49,476]\u001b[0m Trial 8 finished with value: 0.9649835558135036 and parameters: {'max_depth': 36, 'n_estimators': 82}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:09:41,930]\u001b[0m Trial 9 finished with value: 0.9640549429289998 and parameters: {'max_depth': 27, 'n_estimators': 424}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:10:56,720]\u001b[0m Trial 10 finished with value: 0.9639388663184368 and parameters: {'max_depth': 27, 'n_estimators': 651}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:12:08,581]\u001b[0m Trial 11 finished with value: 0.9661056297156123 and parameters: {'max_depth': 50, 'n_estimators': 566}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:12:47,716]\u001b[0m Trial 12 finished with value: 0.9654285161539949 and parameters: {'max_depth': 38, 'n_estimators': 293}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:13:58,349]\u001b[0m Trial 13 finished with value: 0.9656993615786419 and parameters: {'max_depth': 42, 'n_estimators': 536}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:14:37,576]\u001b[0m Trial 14 finished with value: 0.9659895531050493 and parameters: {'max_depth': 50, 'n_estimators': 289}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:15:20,072]\u001b[0m Trial 15 finished with value: 0.9647900947958986 and parameters: {'max_depth': 31, 'n_estimators': 344}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:15:28,215]\u001b[0m Trial 16 finished with value: 0.8078545173147611 and parameters: {'max_depth': 3, 'n_estimators': 206}. Best is trial 0 with value: 0.9661249758173728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:16:32,004]\u001b[0m Trial 17 finished with value: 0.9663377829367382 and parameters: {'max_depth': 43, 'n_estimators': 507}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:17:57,537]\u001b[0m Trial 18 finished with value: 0.9659895531050493 and parameters: {'max_depth': 42, 'n_estimators': 678}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:18:50,985]\u001b[0m Trial 19 finished with value: 0.9552718127297349 and parameters: {'max_depth': 19, 'n_estimators': 506}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:20:08,515]\u001b[0m Trial 20 finished with value: 0.96523505513639 and parameters: {'max_depth': 32, 'n_estimators': 653}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:20:58,515]\u001b[0m Trial 21 finished with value: 0.9660669375120913 and parameters: {'max_depth': 46, 'n_estimators': 371}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:21:57,418]\u001b[0m Trial 22 finished with value: 0.9656413232733604 and parameters: {'max_depth': 40, 'n_estimators': 455}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:23:11,540]\u001b[0m Trial 23 finished with value: 0.9658347842909654 and parameters: {'max_depth': 47, 'n_estimators': 581}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:24:10,115]\u001b[0m Trial 24 finished with value: 0.9650415941187851 and parameters: {'max_depth': 33, 'n_estimators': 463}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:24:56,905]\u001b[0m Trial 25 finished with value: 0.9662797446314567 and parameters: {'max_depth': 50, 'n_estimators': 349}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:25:30,978]\u001b[0m Trial 26 finished with value: 0.9659895531050493 and parameters: {'max_depth': 44, 'n_estimators': 217}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:26:18,567]\u001b[0m Trial 27 finished with value: 0.9659702070032888 and parameters: {'max_depth': 41, 'n_estimators': 336}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:27:23,902]\u001b[0m Trial 28 finished with value: 0.9663184368349778 and parameters: {'max_depth': 50, 'n_estimators': 502}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:28:43,738]\u001b[0m Trial 29 finished with value: 0.9661830141226543 and parameters: {'max_depth': 50, 'n_estimators': 602}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:29:49,271]\u001b[0m Trial 30 finished with value: 0.9660669375120913 and parameters: {'max_depth': 45, 'n_estimators': 509}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:31:05,812]\u001b[0m Trial 31 finished with value: 0.9661443219191332 and parameters: {'max_depth': 50, 'n_estimators': 603}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[32m[I 2023-04-01 16:32:35,214]\u001b[0m Trial 32 finished with value: 0.9661636680208938 and parameters: {'max_depth': 50, 'n_estimators': 711}. Best is trial 17 with value: 0.9663377829367382.\u001b[0m\n",
      "\u001b[33m[W 2023-04-01 16:33:11,318]\u001b[0m Trial 33 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ivershin/venv_venv/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_73520/2619324592.py\", line 14, in objective\n",
      "    dt.fit(X_train, y_train)\n",
      "  File \"/home/ivershin/venv_venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/ivershin/venv_venv/lib/python3.9/site-packages/joblib/parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/ivershin/venv_venv/lib/python3.9/site-packages/joblib/parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 765, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 762, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 574, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create Optuna study and optimize hyperparameters\u001b[39;00m\n\u001b[1;32m     20\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and score\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [23], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     11\u001b[0m dt \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m rnd)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m score \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mscore(X_val, y_val)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/venv_venv/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rnd)\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 800),\n",
    "    }\n",
    "\n",
    "    # Create a Decision Tree Classifier with the hyperparameters\n",
    "    dt = RandomForestClassifier(**params, n_jobs=-1, random_state = rnd)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    dt.fit(X_train, y_train)\n",
    "    score = dt.score(X_val, y_val)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Create Optuna study and optimize hyperparameters\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Score: {trial.value:.3f}')\n",
    "print('  Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea887a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(train, test):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    model = RandomForestClassifier(random_state = rnd, n_estimators=507, max_depth=43, n_jobs=-1)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    X_t = test.drop(['client_id', 'dt','target'],axis=1)\n",
    "    y_t = test['target'].to_numpy()\n",
    "\n",
    "    pred_proba = model.predict_proba(X_t)[:,1]\n",
    "    print('gini: ', round(2*roc_auc_score(y_t, pred_proba)-1,3))\n",
    "    pred = model.predict(X_t)\n",
    "    print('f1_score: ', round(f1_score(y_t, pred),3))\n",
    "    print('f2_score: ',  round(fbeta_score(y_t, pred,beta =2), 3))\n",
    "    print('accuracy_score: ', round(accuracy_score(y_t, pred),3))\n",
    "    print('recall_score: ', round(recall_score(y_t, pred),3))\n",
    "    print('precision_score: ', round(precision_score(y_t, pred),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d210b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini:  0.341\n",
      "f1_score:  0.149\n",
      "f2_score:  0.299\n",
      "accuracy_score:  0.328\n",
      "recall_score:  0.91\n",
      "precision_score:  0.081\n"
     ]
    }
   ],
   "source": [
    "RF(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab557e",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NeSflYLHDiOC",
   "metadata": {
    "id": "NeSflYLHDiOC"
   },
   "source": [
    "Определение гиперпараметров для DecisionTreeCL\n",
    "* что засовывать в параметры подсказывал мне GPT ^_^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cabf2e",
   "metadata": {
    "id": "88cabf2e"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rnd)\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "    }\n",
    "\n",
    "    # Create a Decision Tree Classifier with the hyperparameters\n",
    "    dt = DecisionTreeClassifier(**params, random_state = rnd)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    dt.fit(X_train, y_train)\n",
    "    score = dt.score(X_val, y_val)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Create Optuna study and optimize hyperparameters\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Score: {trial.value:.3f}')\n",
    "print('  Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "678f3a4e",
   "metadata": {
    "id": "678f3a4e"
   },
   "outputs": [],
   "source": [
    "def DTCL(train, test):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    model = DecisionTreeClassifier(random_state = rnd, max_depth=10, min_samples_split= 7, min_samples_leaf = 1, criterion= 'gini')\n",
    "    model.fit(X, y)\n",
    "\n",
    "    X_t = test.drop(['target'],axis=1)\n",
    "    y_t = test['target'].to_numpy()\n",
    "\n",
    "    pred_proba = model.predict_proba(X_t)[:,1]\n",
    "    print('gini: ', round(2*roc_auc_score(y_t, pred_proba)-1,3))\n",
    "    pred = model.predict(X_t)\n",
    "    print('f1_score: ', round(f1_score(y_t, pred),3))\n",
    "    print('f2_score: ',  round(fbeta_score(y_t, pred,beta =2), 3))\n",
    "    print('accuracy_score: ', round(accuracy_score(y_t, pred),3))\n",
    "    print('recall_score: ', round(recall_score(y_t, pred),3))\n",
    "    print('precision_score: ', round(precision_score(y_t, pred),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EORqID3W7-6I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EORqID3W7-6I",
    "outputId": "a1838c95-0a62-45af-a640-1be5fd8e736b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini:  0.614\n",
      "f1_score:  0.325\n",
      "f2_score:  0.466\n",
      "accuracy_score:  0.825\n",
      "recall_score:  0.654\n",
      "precision_score:  0.216\n"
     ]
    }
   ],
   "source": [
    "DTCL(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd674bbf",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "PJkKee_w84gP",
   "metadata": {
    "id": "PJkKee_w84gP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-01 16:36:02,729]\u001b[0m A new study created in memory with name: no-name-2314fe2c-43ff-4b73-bfc1-a70003187e73\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:37:32,735]\u001b[0m Trial 13 finished with value: 0.8592377635906365 and parameters: {'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 0.4229074403799771, 'bootstrap': True}. Best is trial 13 with value: 0.8592377635906365.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:38:56,163]\u001b[0m Trial 9 finished with value: 0.8009286128845038 and parameters: {'n_estimators': 186, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 0.1428839109641513, 'bootstrap': True}. Best is trial 13 with value: 0.8592377635906365.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:40:55,943]\u001b[0m Trial 1 finished with value: 0.7826078545173147 and parameters: {'n_estimators': 775, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 0.13839711440219918, 'bootstrap': True}. Best is trial 13 with value: 0.8592377635906365.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:42:14,158]\u001b[0m Trial 14 finished with value: 0.8947378603211453 and parameters: {'n_estimators': 170, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': 0.24836335347473953, 'bootstrap': True}. Best is trial 14 with value: 0.8947378603211453.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:42:35,220]\u001b[0m Trial 7 finished with value: 0.894060746759528 and parameters: {'n_estimators': 110, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 0.4980611358825021, 'bootstrap': False}. Best is trial 14 with value: 0.8947378603211453.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:43:31,870]\u001b[0m Trial 6 finished with value: 0.82851615399497 and parameters: {'n_estimators': 415, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 0.18150503744066246, 'bootstrap': False}. Best is trial 14 with value: 0.8947378603211453.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:47:17,958]\u001b[0m Trial 10 finished with value: 0.8965563938866319 and parameters: {'n_estimators': 225, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 0.35240125219577656, 'bootstrap': False}. Best is trial 10 with value: 0.8965563938866319.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:47:38,178]\u001b[0m Trial 15 finished with value: 0.8195008705745792 and parameters: {'n_estimators': 357, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 0.8549655202775662, 'bootstrap': False}. Best is trial 10 with value: 0.8965563938866319.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:53:06,980]\u001b[0m Trial 4 finished with value: 0.8971174308376862 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 0.927063776129991, 'bootstrap': True}. Best is trial 4 with value: 0.8971174308376862.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:53:33,770]\u001b[0m Trial 2 finished with value: 0.8669375120913136 and parameters: {'n_estimators': 880, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 0.1118366506813657, 'bootstrap': False}. Best is trial 4 with value: 0.8971174308376862.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:54:58,918]\u001b[0m Trial 19 finished with value: 0.9128458115689688 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 0.8484163210879152, 'bootstrap': False}. Best is trial 19 with value: 0.9128458115689688.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 16:58:27,142]\u001b[0m Trial 20 finished with value: 0.7954343199845231 and parameters: {'n_estimators': 971, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 0.4499351125377432, 'bootstrap': False}. Best is trial 19 with value: 0.9128458115689688.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 17:05:29,979]\u001b[0m Trial 17 finished with value: 0.887966724704972 and parameters: {'n_estimators': 782, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.24704177935584842, 'bootstrap': False}. Best is trial 19 with value: 0.9128458115689688.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 17:06:39,838]\u001b[0m Trial 18 finished with value: 0.8499322886438383 and parameters: {'n_estimators': 532, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 0.9060369119017023, 'bootstrap': True}. Best is trial 19 with value: 0.9128458115689688.\u001b[0m\n",
      "/tmp/ipykernel_73520/652256429.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
      "\u001b[32m[I 2023-04-01 17:07:31,954]\u001b[0m Trial 11 finished with value: 0.897775198297543 and parameters: {'n_estimators': 560, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 0.6272579089791916, 'bootstrap': True}. Best is trial 19 with value: 0.9128458115689688.\u001b[0m\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy() \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=rnd)  \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "    }\n",
    "\n",
    "    # Create an ExtraTrees Classifier with the hyperparameters\n",
    "    et = ExtraTreesClassifier(**params, random_state = rnd, n_jobs=15)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    et.fit(X_train, y_train)\n",
    "    score = et.score(X_val, y_val)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Create Optuna study and optimize hyperparameters\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, n_jobs=15)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Score: {trial.value:.3f}')\n",
    "print('  Params:')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "QLsKBGx8DqTz",
   "metadata": {
    "id": "QLsKBGx8DqTz"
   },
   "outputs": [],
   "source": [
    "def ETCL(train, test):\n",
    "    X = train.drop(['target'],axis=1)\n",
    "    y = train['target'].to_numpy()\n",
    "    model = ExtraTreesClassifier(random_state = rnd, n_jobs=-1, n_estimators =108, max_depth=10, min_samples_split= 2, min_samples_leaf = 7, bootstrap = False, max_features = 0.8484163210879152 )\n",
    "    model.fit(X, y)\n",
    "\n",
    "    X_t = test.drop(['client_id', 'dt','target'],axis=1)\n",
    "    y_t = test['target'].to_numpy()\n",
    "\n",
    "    pred_proba = model.predict_proba(X_t)[:,1]\n",
    "    print('gini: ', round(2*roc_auc_score(y_t, pred_proba)-1,3))\n",
    "    pred = model.predict(X_t)\n",
    "    print('f1_score: ', round(f1_score(y_t, pred),3))\n",
    "    print('f2_score: ',  round(fbeta_score(y_t, pred,beta =2), 3))\n",
    "    print('accuracy_score: ', round(accuracy_score(y_t, pred),3))\n",
    "    print('recall_score: ', round(recall_score(y_t, pred),3))\n",
    "    print('precision_score: ', round(precision_score(y_t, pred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e6f78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini:  0.297\n",
      "f1_score:  0.121\n",
      "f2_score:  0.256\n",
      "accuracy_score:  0.069\n",
      "recall_score:  0.99\n",
      "precision_score:  0.064\n"
     ]
    }
   ],
   "source": [
    "ETCL(train, test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
